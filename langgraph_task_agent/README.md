# LangGraph Task Hierarchy Agent

## 1. Overview

This agent uses LangGraph and AWS Bedrock (specifically, the Anthropic Claude v2 model) to process a Product Requirements Document (PRD) written in Markdown. It breaks down the PRD into a hierarchical list of tasks and outputs this hierarchy in Markdown format.

The agent is designed to:
- Parse an initial PRD.
- Generate top-level tasks.
- Recursively expand tasks into subtasks up to a specified depth.

## 2. Project Structure

- **`run_agent.py`**: The main command-line script to execute the agent.
- **`agent_logic/`**: Contains the core Python modules for the agent:
    - **`agent_graph.py`**: Defines the LangGraph structure, nodes, and edges.
    - **`graph_nodes.py`**: Implements the functions for each node in the graph (e.g., PRD parsing, task expansion).
    - **`bedrock_llm.py`**: Handles interaction with the AWS Bedrock Claude v2 LLM.
    - **`file_utils.py`**: Provides utilities for reading input Markdown PRDs and writing the output task hierarchy in Markdown.
- **`prompts/`**: Contains the prompt templates used by the LLM at different stages of processing. These are Markdown files and can be reviewed and customized.
- **`examples/`**: Intended for sample input PRD files and corresponding output generated by the agent.
- **`requirements.txt`**: Lists the Python dependencies required for the agent.
- **`.env` (template)**: Used for configuring AWS settings (region, credentials). You will need to create this file.

## 3. Setup Instructions

### a. Prerequisites
- Python 3.9 or higher.
- An AWS account with access to Bedrock and specifically the `anthropic.claude-v2` model.

### b. Clone Repository
If this agent is part of a larger repository, ensure you have cloned it.

### c. Create Virtual Environment
It's highly recommended to use a virtual environment:
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

### d. Install Dependencies
Navigate to the `langgraph_task_agent` directory and install the required packages:
```bash
cd langgraph_task_agent  # Or navigate to where this README is located
pip install -r requirements.txt
cd .. # Go back to parent if you cd'd
```
*(Note: If running `run_agent.py` from the root of the main project, ensure the virtual environment is active.)*

### e. AWS Bedrock Configuration

1.  **Configure AWS Credentials:**
    Ensure your environment is configured with AWS credentials that have permissions to invoke Bedrock models. Common methods include:
    - Using the AWS CLI (`aws configure`).
    - Setting environment variables (`AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_SESSION_TOKEN` (if using temporary credentials), `AWS_REGION`).
    - Using an IAM role (e.g., if running on EC2).

2.  **Create `.env` File:**
    Inside the `langgraph_task_agent` directory, create a file named `.env`. This file is used by `bedrock_llm.py` to load AWS configurations.
    Add the following, replacing with your details:

    ```env
    # .env file for langgraph_task_agent
    AWS_REGION=us-east-1 # Or your preferred AWS region with Bedrock Claude v2 access

    # If you are not using an IAM role or AWS CLI profiles for credentials,
    # you can (less securely) add them here. It's generally better to configure
    # credentials through standard AWS mechanisms.
    # AWS_ACCESS_KEY_ID=YOUR_AWS_ACCESS_KEY_ID
    # AWS_SECRET_ACCESS_KEY=YOUR_AWS_SECRET_ACCESS_KEY
    ```
    The `bedrock_llm.py` script is configured to use the `AWS_REGION` from this file or an environment variable. Credentials will typically be picked up by `boto3` from your environment or shared AWS config files.

## 4. Running the Agent

Execute the `run_agent.py` script from the root directory of the `langgraph_task_agent` project or its parent if paths are adjusted.

**Command-line Usage:**
```bash
python langgraph_task_agent/run_agent.py -i <path_to_input_prd.md> -o <path_to_output_tasks.md> [options]
```

**Arguments:**
-   `-i`, `--input-prd PATH`: (Required) Path to the input PRD Markdown file.
-   `-o`, `--output-md PATH`: (Required) Path for the output Markdown file where the task hierarchy will be saved.
-   `-d`, `--max-depth N`: (Optional) Maximum depth for task expansion.
    -   `0`: Only top-level tasks from PRD parsing.
    -   `1`: Top-level tasks and one level of their subtasks.
    -   Default: `1`.
-   `--recursion-limit N`: (Optional) LangGraph recursion limit. Default: `25`.

**Example Command:**
Assuming you are in the directory containing `langgraph_task_agent/`:
```bash
python langgraph_task_agent/run_agent.py \
    -i langgraph_task_agent/examples/sample_prd_1.md \
    -o langgraph_task_agent/examples/generated_tasks_output.md \
    -d 1
```
*(Ensure `sample_prd_1.md` exists or use your own PRD file.)*

## 5. Prompts

The AI prompts used by the agent are located in the `langgraph_task_agent/prompts/` directory. These are Markdown files and define the instructions given to the LLM for various stages like initial PRD parsing, task expansion, etc. You can inspect and potentially customize these prompts to alter the agent's behavior, but be mindful of the expected JSON or text structures outlined within them.

## 6. Development Notes

-   The core agent logic is modularized:
    -   `run_agent.py`: CLI and orchestration.
    -   `agent_graph.py`: LangGraph definition.
    -   `graph_nodes.py`: Node implementations.
    -   `bedrock_llm.py`: AWS Bedrock Claude v2 communication.
    -   `file_utils.py`: Markdown input/output.
-   Some modules (e.g., `file_utils.py`, `graph_nodes.py`, `bedrock_llm.py`) contain `if __name__ == '__main__':` blocks for basic, isolated testing of their functionalities. You can run them directly, e.g.:
    ```bash
    python langgraph_task_agent/agent_logic/file_utils.py
    ```
    (Note: Tests involving `bedrock_llm.py` will require AWS credentials and Bedrock access.)
